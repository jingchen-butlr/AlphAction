# SlowFast Finetuning Workflow Diagram

## Visual Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FINETUNING WORKFLOW                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. PREPARATION  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â–º Download Pretrained Model
         â”‚    â””â”€â–º data/models/pretrained_models/SlowFast-ResNet50-4x16.pth
         â”‚
         â”œâ”€â”€â–º Prepare Dataset
         â”‚    â”œâ”€â–º Option A: Use AVA Dataset (DATA.md)
         â”‚    â””â”€â–º Option B: Custom Dataset (CUSTOM_DATASET_PREPARATION.md)
         â”‚
         â””â”€â”€â–º Setup Environment
              â””â”€â–º source activate_uv_env.sh

                         â†“

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. REGISTRATION â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â””â”€â”€â–º Edit alphaction/config/paths_catalog.py
              â””â”€â–º Register your dataset:
                  - video_root
                  - ann_file
                  - box_file

                         â†“

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. CONFIGURATIONâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â–º Option A: Generate Config
         â”‚    â””â”€â–º python tools/generate_finetune_config.py --interactive
         â”‚
         â””â”€â”€â–º Option B: Copy & Edit Config
              â””â”€â–º cp config_files/resnet50_4x16f_baseline.yaml config_files/my_config.yaml
              â””â”€â–º Edit: NUM_CLASSES, DATASETS, OUTPUT_DIR

                         â†“

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. TRAINING     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â–º Option A: Quick Launch
         â”‚    â””â”€â–º bash cursor_readme/finetune_quickstart.sh config_files/my_config.yaml --num-gpus 4
         â”‚
         â””â”€â”€â–º Option B: Manual Launch
              â”œâ”€â–º Single GPU:
              â”‚   â””â”€â–º python train_net.py --config-file config_files/my_config.yaml --transfer --no-head
              â”‚
              â””â”€â–º Multi-GPU:
                  â””â”€â–º python -m torch.distributed.launch --nproc_per_node=4 train_net.py --config-file config_files/my_config.yaml --transfer --no-head

                         â†“

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. MONITORING   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â–º TensorBoard
         â”‚    â””â”€â–º tensorboard --logdir=data/output/my_experiment
         â”‚
         â”œâ”€â”€â–º Watch Logs
         â”‚    â””â”€â–º tail -f data/output/my_experiment/log.txt
         â”‚
         â””â”€â”€â–º Check GPU Usage
              â””â”€â–º watch -n 1 nvidia-smi

                         â†“

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. EVALUATION   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â””â”€â”€â–º Test Model
              â””â”€â–º python test_net.py --config-file config_files/my_config.yaml \
                  MODEL.WEIGHT data/output/my_experiment/model_final.pth

                         â†“

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. ITERATION    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â–º Analyze Results
         â”‚    â””â”€â–º Check per-class performance
         â”‚
         â”œâ”€â”€â–º Adjust Hyperparameters
         â”‚    â”œâ”€â–º Learning rate
         â”‚    â”œâ”€â–º Training iterations
         â”‚    â””â”€â–º Data augmentation
         â”‚
         â””â”€â”€â–º Resume Training or Start New Experiment
              â””â”€â–º bash cursor_readme/finetune_quickstart.sh config_files/my_config.yaml --resume
```

---

## Decision Tree

```
                    START
                      â”‚
                      â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Do you have dataset?  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 â”‚
       YES               NO
        â”‚                 â”‚
        â”‚                 â””â”€â”€â–º Collect & Annotate Data
        â”‚                      â””â”€â”€â–º Follow CUSTOM_DATASET_PREPARATION.md
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Same 80 classes?  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”œâ”€â”€â–º YES â”€â”€â–º Use config without modifications
     â”‚            â””â”€â”€â–º Don't use --no-head flag
     â”‚
     â””â”€â”€â–º NO  â”€â”€â–º Update NUM_CLASSES in config
                  â””â”€â”€â–º Use --no-head flag

                      â”‚
                      â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  GPU availability?  â”‚
         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”œâ”€â”€â–º 1 GPU  â”€â”€â–º VIDEOS_PER_BATCH=2, BASE_LR=0.00005
              â”œâ”€â”€â–º 4 GPUs â”€â”€â–º VIDEOS_PER_BATCH=8, BASE_LR=0.0002
              â””â”€â”€â–º 8 GPUs â”€â”€â–º Use default config values

                      â”‚
                      â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Backbone selection? â”‚
         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”œâ”€â”€â–º Fast/Light â”€â”€â–º ResNet50-4x16
              â””â”€â”€â–º Accurate   â”€â”€â–º ResNet101-8x8

                      â”‚
                      â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Multi-person focus? â”‚
         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”œâ”€â”€â–º YES â”€â”€â–º Enable IA Structure (Dense Serial)
              â””â”€â”€â–º NO  â”€â”€â–º Baseline (IA_STRUCTURE.ACTIVE=False)

                      â”‚
                      â–¼
                START TRAINING!
```

---

## File Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       INPUT FILES                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

data/models/pretrained_models/
â”œâ”€â”€ SlowFast-ResNet50-4x16.pth â”€â”€â”€â”€â”€â”
â””â”€â”€ SlowFast-ResNet101-8x8.pth      â”‚
                                    â”‚
data/YOUR_DATASET/                  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”œâ”€â”€ clips/                          â”œâ”€â–ºâ”‚                â”‚
â”‚   â”œâ”€â”€ train/                      â”‚  â”‚                â”‚
â”‚   â””â”€â”€ val/                        â”‚  â”‚                â”‚
â”œâ”€â”€ keyframes/                      â”‚  â”‚  TRAINING      â”‚
â”‚   â”œâ”€â”€ train/                      â”œâ”€â–ºâ”‚   PROCESS      â”‚
â”‚   â””â”€â”€ val/                        â”‚  â”‚                â”‚
â””â”€â”€ annotations/                    â”‚  â”‚                â”‚
    â”œâ”€â”€ train.json â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚                â”‚
    â””â”€â”€ val.json â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚
config_files/                                  â”‚
â””â”€â”€ my_config.yaml â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚
                                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      OUTPUT FILES                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

data/output/my_experiment/
â”œâ”€â”€ log.txt                    # Training log
â”œâ”€â”€ last_checkpoint            # Path to last checkpoint
â”œâ”€â”€ model_0010000.pth         # Checkpoint at 10K iters
â”œâ”€â”€ model_0020000.pth         # Checkpoint at 20K iters
â”œâ”€â”€ model_final.pth           # Final model
â””â”€â”€ events.out.tfevents.*     # TensorBoard logs
```

---

## Time Estimation

```
TYPICAL TIMELINE FOR FINETUNING PROJECT

Day 1: Setup (2-4 hours)
â”œâ”€â”€ Environment setup              [30 min]
â”œâ”€â”€ Download pretrained models     [20 min]
â”œâ”€â”€ Data preparation              [1-2 hours]
â””â”€â”€ Initial testing               [30 min]

Day 2-3: Training (24-48 hours)
â”œâ”€â”€ Baseline training            [24 hours on 8x V100]
â”œâ”€â”€ Monitoring & validation       [periodic checks]
â””â”€â”€ Checkpoint saving            [automatic]

Day 4: Analysis & Iteration (4-8 hours)
â”œâ”€â”€ Evaluate results             [1 hour]
â”œâ”€â”€ Analyze per-class performance [2 hours]
â”œâ”€â”€ Adjust hyperparameters       [1 hour]
â””â”€â”€ Resume training              [4+ hours]

TOTAL: ~4-5 days for complete cycle
```

---

## Resource Requirements

```
MINIMUM REQUIREMENTS
â”œâ”€â”€ GPU: 1x NVIDIA GPU with 11GB+ VRAM
â”œâ”€â”€ CPU: 8+ cores
â”œâ”€â”€ RAM: 32GB
â”œâ”€â”€ Storage: 500GB SSD
â””â”€â”€ Time: 48+ hours for training

RECOMMENDED SETUP
â”œâ”€â”€ GPU: 4-8x NVIDIA V100/A100
â”œâ”€â”€ CPU: 32+ cores
â”œâ”€â”€ RAM: 128GB
â”œâ”€â”€ Storage: 1TB+ NVMe SSD
â””â”€â”€ Time: 24-36 hours for training

STORAGE BREAKDOWN
â”œâ”€â”€ Pretrained models: ~500MB
â”œâ”€â”€ AVA dataset: ~50GB
â”œâ”€â”€ Checkpoints: ~10GB per experiment
â”œâ”€â”€ Logs & results: ~1GB
â””â”€â”€ Custom dataset: varies (typically 20-100GB)
```

---

## Common Paths Through Documentation

```
PATH 1: EXPERIENCED USER (Quick Start)
1. FINETUNING_INDEX.md          [2 min]
2. FINETUNING_QUICK_REFERENCE.md [5 min]
3. generate_finetune_config.py   [2 min]
4. finetune_quickstart.sh        [1 min]
   Total: ~10 minutes to start training

PATH 2: BEGINNER (Comprehensive)
1. FINETUNING_INDEX.md           [5 min]
2. FINETUNING_GUIDE.md           [30 min]
3. CUSTOM_DATASET_PREPARATION.md [20 min]
4. Practice with AVA dataset     [60 min]
5. Try custom dataset            [120 min]
   Total: ~3.5 hours to full understanding

PATH 3: TROUBLESHOOTING (Problem Solving)
1. Identify problem
2. FINETUNING_TROUBLESHOOTING.md [variable]
3. Apply solution
4. Resume training
   Total: varies by issue

PATH 4: CUSTOM DATASET (From Scratch)
1. FINETUNING_INDEX.md                   [5 min]
2. CUSTOM_DATASET_PREPARATION.md         [20 min]
3. Prepare data                          [2-4 hours]
4. FINETUNING_GUIDE.md (Dataset section) [15 min]
5. generate_finetune_config.py           [5 min]
6. Start training                        [5 min]
   Total: ~3-5 hours before training
```

---

## Success Metrics

```
TRAINING PROGRESS INDICATORS

Good Training:
â”œâ”€â”€ Loss decreases steadily
â”œâ”€â”€ Validation mAP increases
â”œâ”€â”€ GPU utilization > 80%
â”œâ”€â”€ No NaN/Inf in losses
â””â”€â”€ Checkpoints saving successfully

Warning Signs:
â”œâ”€â”€ Loss plateaus early
â”œâ”€â”€ Validation mAP drops
â”œâ”€â”€ GPU utilization < 50%
â”œâ”€â”€ Frequent OOM errors
â””â”€â”€ Loss becomes NaN

FINAL EVALUATION TARGETS

For AVA v2.2:
â”œâ”€â”€ ResNet50 Baseline: 26-27 mAP
â”œâ”€â”€ ResNet50 + IA: 29-30 mAP
â”œâ”€â”€ ResNet101 Baseline: 28-29 mAP
â””â”€â”€ ResNet101 + IA: 31-32 mAP

For Custom Dataset:
â”œâ”€â”€ Depends on dataset difficulty
â”œâ”€â”€ Compare to baseline (no pretrain)
â”œâ”€â”€ Should see 2-3x improvement with pretrain
â””â”€â”€ Monitor per-class performance
```

---

## Command Cheatsheet

```bash
# GENERATE CONFIG
python tools/generate_finetune_config.py --interactive

# TRAINING
# Single GPU, new classes
python train_net.py \
  --config-file config_files/my_config.yaml \
  --transfer --no-head --use-tfboard \
  SOLVER.VIDEOS_PER_BATCH 2

# Multi-GPU (4 GPUs)
python -m torch.distributed.launch --nproc_per_node=4 \
  train_net.py \
  --config-file config_files/my_config.yaml \
  --transfer --no-head --use-tfboard

# Using quickstart script
bash cursor_readme/finetune_quickstart.sh \
  config_files/my_config.yaml \
  --num-gpus 4 --new-classes

# MONITORING
tensorboard --logdir=data/output/my_experiment
tail -f data/output/my_experiment/log.txt
watch -n 1 nvidia-smi

# EVALUATION
python test_net.py \
  --config-file config_files/my_config.yaml \
  MODEL.WEIGHT data/output/my_experiment/model_final.pth

# RESUME TRAINING
bash cursor_readme/finetune_quickstart.sh \
  config_files/my_config.yaml \
  --num-gpus 4 --resume
```

---

## Quick Troubleshooting

```
PROBLEM                         QUICK FIX
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Out of Memory                   SOLVER.VIDEOS_PER_BATCH 1
Loss is NaN                     SOLVER.BASE_LR 0.0001 (reduce)
Training too slow               DATALOADER.NUM_WORKERS 8
Dataset not found               Check paths_catalog.py
Low accuracy                    Train longer (MAX_ITER)
Wrong number of classes         Update NUM_CLASSES, use --no-head
Model not loading               Check MODEL.WEIGHT path
```

---

## Next Steps

After reviewing this workflow:

1. **Go to** [FINETUNING_INDEX.md](FINETUNING_INDEX.md) for navigation
2. **Choose** your path based on experience level
3. **Follow** the appropriate guide
4. **Use** the tools to simplify setup
5. **Start** training!

---

**Remember**: The key to successful finetuning is:
- âœ… Good quality data
- âœ… Proper configuration
- âœ… Patient monitoring
- âœ… Iterative improvement

Happy Finetuning! ðŸš€

